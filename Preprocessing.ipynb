{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd29df58",
   "metadata": {},
   "source": [
    "### Preprocessing & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c8c1ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: 349 samples × 51 features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>AFP</th>\n",
       "      <th>AG</th>\n",
       "      <th>Age</th>\n",
       "      <th>ALB</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>BASO#</th>\n",
       "      <th>BASO%</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Ca</th>\n",
       "      <th>CA125</th>\n",
       "      <th>CA19-9</th>\n",
       "      <th>CA72-4</th>\n",
       "      <th>CEA</th>\n",
       "      <th>CL</th>\n",
       "      <th>CO2CP</th>\n",
       "      <th>CREA</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>DBIL</th>\n",
       "      <th>EO#</th>\n",
       "      <th>EO%</th>\n",
       "      <th>GGT</th>\n",
       "      <th>GLO</th>\n",
       "      <th>GLU.</th>\n",
       "      <th>HCT</th>\n",
       "      <th>HE4</th>\n",
       "      <th>HGB</th>\n",
       "      <th>IBIL</th>\n",
       "      <th>K</th>\n",
       "      <th>LYM#</th>\n",
       "      <th>LYM%</th>\n",
       "      <th>MCH</th>\n",
       "      <th>MCV</th>\n",
       "      <th>Menopause</th>\n",
       "      <th>Mg</th>\n",
       "      <th>MONO#</th>\n",
       "      <th>MONO%</th>\n",
       "      <th>MPV</th>\n",
       "      <th>Na</th>\n",
       "      <th>NEU</th>\n",
       "      <th>PCT</th>\n",
       "      <th>PDW</th>\n",
       "      <th>PHOS</th>\n",
       "      <th>PLT</th>\n",
       "      <th>RBC</th>\n",
       "      <th>RDW</th>\n",
       "      <th>TBIL</th>\n",
       "      <th>TP</th>\n",
       "      <th>UA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.58\\t</td>\n",
       "      <td>19.36</td>\n",
       "      <td>47</td>\n",
       "      <td>45.4</td>\n",
       "      <td>56.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5.35</td>\n",
       "      <td>2.48</td>\n",
       "      <td>15.36\\t</td>\n",
       "      <td>36.48\\t</td>\n",
       "      <td>6.42</td>\n",
       "      <td>1.40</td>\n",
       "      <td>107.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0.273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.36</td>\n",
       "      <td>0.65</td>\n",
       "      <td>16.8</td>\n",
       "      <td>33.7</td>\n",
       "      <td>103.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.22</td>\n",
       "      <td>5.70</td>\n",
       "      <td>11.70</td>\n",
       "      <td>141.3</td>\n",
       "      <td>76.2</td>\n",
       "      <td>0.09</td>\n",
       "      <td>13.4</td>\n",
       "      <td>1.46</td>\n",
       "      <td>74</td>\n",
       "      <td>2.64</td>\n",
       "      <td>13.7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>73.9</td>\n",
       "      <td>396.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>34.24\\t</td>\n",
       "      <td>23.98</td>\n",
       "      <td>61</td>\n",
       "      <td>39.9</td>\n",
       "      <td>95.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.30</td>\n",
       "      <td>3.21</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2444.00\\t</td>\n",
       "      <td>19.98\\t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.46</td>\n",
       "      <td>100.1</td>\n",
       "      <td>22.3</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.50</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.1</td>\n",
       "      <td>10.50</td>\n",
       "      <td>0.417</td>\n",
       "      <td>934.10</td>\n",
       "      <td>128.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.27</td>\n",
       "      <td>17.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>85.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.41</td>\n",
       "      <td>5.50</td>\n",
       "      <td>10.00</td>\n",
       "      <td>142.0</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.30</td>\n",
       "      <td>11.2</td>\n",
       "      <td>1.09</td>\n",
       "      <td>304</td>\n",
       "      <td>4.89</td>\n",
       "      <td>12.7</td>\n",
       "      <td>6.8</td>\n",
       "      <td>72.0</td>\n",
       "      <td>119.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.50\\t</td>\n",
       "      <td>18.40</td>\n",
       "      <td>39</td>\n",
       "      <td>45.4</td>\n",
       "      <td>77.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.60</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.57</td>\n",
       "      <td>56.08\\t</td>\n",
       "      <td>12.18\\t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.77</td>\n",
       "      <td>102.6</td>\n",
       "      <td>22.2</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.60</td>\n",
       "      <td>10.0</td>\n",
       "      <td>32.5</td>\n",
       "      <td>4.64</td>\n",
       "      <td>0.391</td>\n",
       "      <td>47.56</td>\n",
       "      <td>131.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>4.30</td>\n",
       "      <td>1.10</td>\n",
       "      <td>23.7</td>\n",
       "      <td>28.4</td>\n",
       "      <td>84.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5.40</td>\n",
       "      <td>11.40</td>\n",
       "      <td>138.9</td>\n",
       "      <td>69.7</td>\n",
       "      <td>0.13</td>\n",
       "      <td>15.2</td>\n",
       "      <td>0.97</td>\n",
       "      <td>112</td>\n",
       "      <td>4.62</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.8</td>\n",
       "      <td>77.9</td>\n",
       "      <td>209.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.75</td>\n",
       "      <td>16.60</td>\n",
       "      <td>45</td>\n",
       "      <td>39.2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.74</td>\n",
       "      <td>5.27</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2555</td>\n",
       "      <td>18.41</td>\n",
       "      <td>131.60</td>\n",
       "      <td>0.82</td>\n",
       "      <td>103.2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>65.7</td>\n",
       "      <td>0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>17.0</td>\n",
       "      <td>26.9</td>\n",
       "      <td>4.76</td>\n",
       "      <td>0.372</td>\n",
       "      <td>853.50</td>\n",
       "      <td>123.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>1.73</td>\n",
       "      <td>27.2</td>\n",
       "      <td>30.6</td>\n",
       "      <td>92.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.42</td>\n",
       "      <td>6.55</td>\n",
       "      <td>7.38</td>\n",
       "      <td>139.1</td>\n",
       "      <td>65.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>17.4</td>\n",
       "      <td>1.25</td>\n",
       "      <td>339</td>\n",
       "      <td>4.01</td>\n",
       "      <td>14.6</td>\n",
       "      <td>10.9</td>\n",
       "      <td>66.1</td>\n",
       "      <td>215.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.36</td>\n",
       "      <td>19.97</td>\n",
       "      <td>45</td>\n",
       "      <td>35.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>4.89</td>\n",
       "      <td>2.48</td>\n",
       "      <td>1391</td>\n",
       "      <td>11.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.42</td>\n",
       "      <td>99.6</td>\n",
       "      <td>26.2</td>\n",
       "      <td>70.3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.60</td>\n",
       "      <td>24.0</td>\n",
       "      <td>31.5</td>\n",
       "      <td>4.07</td>\n",
       "      <td>0.383</td>\n",
       "      <td>404.90</td>\n",
       "      <td>122.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.77</td>\n",
       "      <td>1.98</td>\n",
       "      <td>28.8</td>\n",
       "      <td>27.7</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.69</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.40</td>\n",
       "      <td>141.0</td>\n",
       "      <td>59.5</td>\n",
       "      <td>0.28</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.94</td>\n",
       "      <td>272</td>\n",
       "      <td>4.40</td>\n",
       "      <td>13.4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>66.5</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID      AFP     AG  Age   ALB   ALP   ALT   AST  BASO#  BASO%  \\\n",
       "0           1   3.58\\t  19.36   47  45.4  56.0  11.0  24.0   0.01   0.30   \n",
       "1           2  34.24\\t  23.98   61  39.9  95.0   9.0  13.0   0.02   0.30   \n",
       "2           3   1.50\\t  18.40   39  45.4  77.0   9.0  18.0   0.03   0.60   \n",
       "3           4     2.75  16.60   45  39.2  26.0  16.0  17.0   0.05   0.74   \n",
       "4           5     2.36  19.97   45  35.0  47.0  21.0  27.0   0.01   0.10   \n",
       "\n",
       "    BUN    Ca      CA125   CA19-9  CA72-4   CEA     CL  CO2CP   CREA  TYPE  \\\n",
       "0  5.35  2.48    15.36\\t  36.48\\t    6.42  1.40  107.4   19.9  103.0     0   \n",
       "1  3.21  2.62  2444.00\\t  19.98\\t     NaN  2.46  100.1   22.3   45.0     0   \n",
       "2  3.80  2.57    56.08\\t  12.18\\t     NaN  0.77  102.6   22.2   48.0     0   \n",
       "3  5.27  2.35       2555    18.41  131.60  0.82  103.2   24.0   65.7     0   \n",
       "4  4.89  2.48       1391    11.15     NaN  0.42   99.6   26.2   70.3     0   \n",
       "\n",
       "   DBIL   EO#   EO%   GGT   GLO   GLU.    HCT     HE4    HGB  IBIL     K  \\\n",
       "0   2.0  0.04  1.00  16.0  28.5   4.67  0.273     NaN   89.0   3.5  5.36   \n",
       "1   2.6  0.04  0.50  13.0  32.1  10.50  0.417  934.10  128.0   4.2  4.38   \n",
       "2   4.7  0.03  0.60  10.0  32.5   4.64  0.391   47.56  131.0  10.1  4.30   \n",
       "3   2.9  0.00  0.07  17.0  26.9   4.76  0.372  853.50  123.0   8.0  4.70   \n",
       "4   2.2  0.11  1.60  24.0  31.5   4.07  0.383  404.90  122.0   3.1  4.77   \n",
       "\n",
       "   LYM#  LYM%   MCH    MCV  Menopause    Mg  MONO#  MONO%    MPV     Na   NEU  \\\n",
       "0  0.65  16.8  33.7  103.4          0  0.78   0.22   5.70  11.70  141.3  76.2   \n",
       "1  1.27  17.2  26.2   85.3          1  0.82   0.41   5.50  10.00  142.0  76.5   \n",
       "2  1.10  23.7  28.4   84.6          0  1.00   0.25   5.40  11.40  138.9  69.7   \n",
       "3  1.73  27.2  30.6   92.6          1  1.11   0.42   6.55   7.38  139.1  65.5   \n",
       "4  1.98  28.8  27.7   87.0          0  1.08   0.69  10.00  10.40  141.0  59.5   \n",
       "\n",
       "    PCT   PDW  PHOS  PLT   RBC   RDW  TBIL    TP     UA  \n",
       "0  0.09  13.4  1.46   74  2.64  13.7   5.5  73.9  396.4  \n",
       "1  0.30  11.2  1.09  304  4.89  12.7   6.8  72.0  119.2  \n",
       "2  0.13  15.2  0.97  112  4.62  12.0  14.8  77.9  209.2  \n",
       "3  0.25  17.4  1.25  339  4.01  14.6  10.9  66.1  215.6  \n",
       "4  0.28  11.9  0.94  272  4.40  13.4   5.3  66.5  206.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned dataset\n",
    "data = pd.read_excel(r\"C:\\Ovarian Cancer Prediction\\Supplementary data 1.xlsx\")\n",
    "\n",
    "# Display dataset dimensions\n",
    "print(f\"Dataset shape: {data.shape[0]:,} samples × {data.shape[1]} features\")\n",
    "\n",
    "# Configure display for full column visibility\n",
    "pd.set_option('display.max_columns', None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04eeddd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 349 entries, 0 to 348\n",
      "Data columns (total 51 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   SUBJECT_ID  349 non-null    int64  \n",
      " 1   AFP         327 non-null    object \n",
      " 2   AG          348 non-null    float64\n",
      " 3   Age         349 non-null    int64  \n",
      " 4   ALB         339 non-null    float64\n",
      " 5   ALP         339 non-null    float64\n",
      " 6   ALT         339 non-null    float64\n",
      " 7   AST         339 non-null    float64\n",
      " 8   BASO#       349 non-null    float64\n",
      " 9   BASO%       349 non-null    float64\n",
      " 10  BUN         349 non-null    float64\n",
      " 11  Ca          349 non-null    float64\n",
      " 12  CA125       332 non-null    object \n",
      " 13  CA19-9      325 non-null    object \n",
      " 14  CA72-4      109 non-null    float64\n",
      " 15  CEA         327 non-null    float64\n",
      " 16  CL          349 non-null    float64\n",
      " 17  CO2CP       348 non-null    float64\n",
      " 18  CREA        349 non-null    float64\n",
      " 19  TYPE        349 non-null    int64  \n",
      " 20  DBIL        339 non-null    float64\n",
      " 21  EO#         349 non-null    float64\n",
      " 22  EO%         349 non-null    float64\n",
      " 23  GGT         339 non-null    float64\n",
      " 24  GLO         339 non-null    float64\n",
      " 25  GLU.        349 non-null    float64\n",
      " 26  HCT         349 non-null    float64\n",
      " 27  HE4         329 non-null    float64\n",
      " 28  HGB         349 non-null    float64\n",
      " 29  IBIL        339 non-null    float64\n",
      " 30  K           349 non-null    float64\n",
      " 31  LYM#        349 non-null    float64\n",
      " 32  LYM%        349 non-null    float64\n",
      " 33  MCH         349 non-null    float64\n",
      " 34  MCV         349 non-null    float64\n",
      " 35  Menopause   349 non-null    int64  \n",
      " 36  Mg          349 non-null    float64\n",
      " 37  MONO#       349 non-null    float64\n",
      " 38  MONO%       349 non-null    float64\n",
      " 39  MPV         347 non-null    float64\n",
      " 40  Na          349 non-null    float64\n",
      " 41  NEU         258 non-null    float64\n",
      " 42  PCT         347 non-null    float64\n",
      " 43  PDW         347 non-null    float64\n",
      " 44  PHOS        349 non-null    float64\n",
      " 45  PLT         349 non-null    int64  \n",
      " 46  RBC         349 non-null    float64\n",
      " 47  RDW         349 non-null    float64\n",
      " 48  TBIL        339 non-null    float64\n",
      " 49  TP          339 non-null    float64\n",
      " 50  UA          349 non-null    float64\n",
      "dtypes: float64(43), int64(5), object(3)\n",
      "memory usage: 139.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0f2def4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains missing values: True\n",
      "\n",
      "Missing values per feature:\n",
      "AFP        22\n",
      "AG          1\n",
      "ALB        10\n",
      "ALP        10\n",
      "ALT        10\n",
      "AST        10\n",
      "CA125      17\n",
      "CA19-9     24\n",
      "CA72-4    240\n",
      "CEA        22\n",
      "CO2CP       1\n",
      "DBIL       10\n",
      "GGT        10\n",
      "GLO        10\n",
      "HE4        20\n",
      "IBIL       10\n",
      "MPV         2\n",
      "NEU        91\n",
      "PCT         2\n",
      "PDW         2\n",
      "TBIL       10\n",
      "TP         10\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "has_missing = data.isnull().any().any()\n",
    "print(f\"Dataset contains missing values: {has_missing}\")\n",
    "\n",
    "# Summarize missing values per feature\n",
    "missing_summary = data.isnull().sum()\n",
    "print(\"\\nMissing values per feature:\")\n",
    "print(missing_summary[missing_summary > 0])  # Show only features with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c487257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================================================\n",
      "STEP 1: DATA LOADING AND PREPROCESSING\n",
      "========================================================================================================================\n",
      "Dataset: 349 samples, 49 features\n",
      "Class distribution: Benign: 171, Malignant: 178\n",
      "Total features: 54\n",
      "Name of all features: \n",
      "AFP\n",
      "AG\n",
      "Age\n",
      "ALB\n",
      "ALP\n",
      "ALT\n",
      "AST\n",
      "BASO#\n",
      "BASO%\n",
      "BUN\n",
      "Ca\n",
      "CA125\n",
      "CA19-9\n",
      "CEA\n",
      "CL\n",
      "CO2CP\n",
      "CREA\n",
      "DBIL\n",
      "EO#\n",
      "EO%\n",
      "GGT\n",
      "GLO\n",
      "GLU.\n",
      "HCT\n",
      "HE4\n",
      "HGB\n",
      "IBIL\n",
      "K\n",
      "LYM#\n",
      "LYM%\n",
      "MCH\n",
      "MCV\n",
      "Menopause\n",
      "Mg\n",
      "MONO#\n",
      "MONO%\n",
      "MPV\n",
      "Na\n",
      "NEU\n",
      "PCT\n",
      "PDW\n",
      "PHOS\n",
      "PLT\n",
      "RBC\n",
      "RDW\n",
      "TBIL\n",
      "TP\n",
      "UA\n",
      "AFP_missing\n",
      "CA125_missing\n",
      "CA19-9_missing\n",
      "CEA_missing\n",
      "HE4_missing\n",
      "NEU_missing\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: DATA LOADING AND PREPROCESSING\n",
    "\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"STEP 1: DATA LOADING AND PREPROCESSING\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "X = data.drop(columns=['TYPE', 'SUBJECT_ID'])\n",
    "y = data['TYPE']\n",
    "\n",
    "print(f\"Dataset: {data.shape[0]} samples, {X.shape[1]} features\")\n",
    "print(f\"Class distribution: Benign: {(y==0).sum()}, Malignant: {(y==1).sum()}\")\n",
    "\n",
    "def clean_numeric(series):\n",
    "    if series.dtype == 'object':\n",
    "        return pd.to_numeric(\n",
    "            series.astype(str).str.replace(r'[^\\d\\\\.\\\\-eE]', '', regex=True).str.strip(),\n",
    "            errors='coerce'\n",
    "        )\n",
    "    return series\n",
    "\n",
    "X = X.apply(clean_numeric)\n",
    "\n",
    "# Drop CA72-4 becuase it has 69% of missing data\n",
    "if 'CA72-4' in X.columns:\n",
    "    X = X.drop(columns=['CA72-4'])\n",
    "\n",
    "# Derive NEU% from complementary percentages if possible\n",
    "pct_complements = ['LYM%', 'MONO%', 'EO%', 'BASO%']\n",
    "if all(col in X.columns for col in pct_complements):\n",
    "    neu_derived = 100 - X[pct_complements].sum(axis=1)\n",
    "    mask = X['NEU'].isna() & neu_derived.between(0, 100)\n",
    "    X.loc[mask, 'NEU'] = neu_derived[mask]\n",
    "\n",
    "# Create missingness indicators for key biomarkers\n",
    "for col in ['AFP', 'CA125', 'CA19-9', 'CEA', 'HE4', 'NEU']:\n",
    "    if col in X.columns:\n",
    "        X[f'{col}_missing'] = X[col].isna().astype(int)\n",
    "\n",
    "print(f\"Total features: {X.shape[1]}\")\n",
    "print(\"Name of all features: \")\n",
    "for col in X.columns:\n",
    "    print(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "248c5dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================================================\n",
      "STEP 2: STRATIFIED TRAIN-TEST SPLIT\n",
      "========================================================================================================================\n",
      "Training: 279 samples, Test: 70 samples\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: TRAIN-TEST SPLIT\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"STEP 2: STRATIFIED TRAIN-TEST SPLIT\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Training: {X_train.shape[0]} samples, Test: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b77efa39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================================================================\n",
      "STEP 3: PREPROCESSING (LOG TRANSFORM, IMPUTATION, SCALING)\n",
      "========================================================================================================================\n",
      "Preprocessing complete\n",
      "Data cleaning and imputation complete. Saved to 'cleaned_dataset.csv'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# STEP 3: PREPROCESSING\n",
    "\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"STEP 3: PREPROCESSING (LOG TRANSFORM, IMPUTATION, SCALING)\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "tumor_markers = [col for col in ['AFP', 'CA125', 'CA19-9', 'CEA', 'HE4'] if col in X_train.columns]\n",
    "\n",
    "for col in tumor_markers:\n",
    "    X_train[col] = np.log1p(X_train[col])\n",
    "    X_test[col] = np.log1p(X_test[col])\n",
    "\n",
    "knn_imputer = KNNImputer(n_neighbors=5, weights='distance')\n",
    "X_train[tumor_markers] = knn_imputer.fit_transform(X_train[tumor_markers])\n",
    "X_test[tumor_markers] = knn_imputer.transform(X_test[tumor_markers])\n",
    "\n",
    "clinical_features = [col for col in X_train.columns\n",
    "                     if col not in tumor_markers and not col.endswith('_missing')\n",
    "                     and X_train[col].dtype in ['float64', 'int64']]\n",
    "\n",
    "median_imputer = SimpleImputer(strategy='median')\n",
    "X_train[clinical_features] = median_imputer.fit_transform(X_train[clinical_features])\n",
    "X_test[clinical_features] = median_imputer.transform(X_test[clinical_features])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(f\"Preprocessing complete\")\n",
    "\n",
    "# Save processed dataset\n",
    "processed_data = pd.concat([X_train_scaled, y_train], axis=1)\n",
    "processed_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Data cleaning and imputation complete. Saved to '{output_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c093b76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values Comparison (Before vs After):\n",
      "         Initial Missing  Remaining Missing\n",
      "AFP                  22                  0\n",
      "AG                    1                  0\n",
      "ALB                  10                  0\n",
      "ALP                  10                  0\n",
      "ALT                  10                  0\n",
      "AST                  10                  0\n",
      "CA125                17                  0\n",
      "CA19-9               24                  0\n",
      "CEA                  22                  0\n",
      "CO2CP                 1                  0\n",
      "DBIL                 10                  0\n",
      "GGT                  10                  0\n",
      "GLO                  10                  0\n",
      "HE4                  20                  0\n",
      "IBIL                 10                  0\n",
      "MPV                   2                  0\n",
      "NEU                  91                  0\n",
      "PCT                   2                  0\n",
      "PDW                   2                  0\n",
      "TBIL                 10                  0\n",
      "TP                   10                  0\n"
     ]
    }
   ],
   "source": [
    "initial_missing = data.isna().sum()\n",
    "remaining_missing = processed_data.isna().sum()\n",
    "\n",
    "valid_columns = initial_missing.index.intersection(remaining_missing.index)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    \"Initial Missing\": initial_missing[valid_columns],\n",
    "    \"Remaining Missing\": remaining_missing[valid_columns]\n",
    "})\n",
    "\n",
    "comparison = comparison[comparison[\"Initial Missing\"] > 0]\n",
    "\n",
    "print(\"\\nMissing Values Comparison (Before vs After):\\n\", comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ca7773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning and imputation complete. Saved to 'ovarian_cleaned_dataset.csv'.\n",
      "Remaining missing values:\n",
      " Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define numeric columns (exclude identifiers/categoricals)\n",
    "num_cols = [col for col in data.columns if col not in ['TYPE', 'Menopause']]\n",
    "\n",
    "def clean_numeric(series):\n",
    "    \"\"\"Clean non-numeric characters and coerce to numeric.\"\"\"\n",
    "    return pd.to_numeric(\n",
    "        series.astype(str).str.replace(r'[^\\d\\.\\-eE]', '', regex=True).str.strip(),\n",
    "        errors='coerce'\n",
    "    )\n",
    "\n",
    "# Clean numeric columns\n",
    "data[num_cols] = data[num_cols].apply(clean_numeric)\n",
    "\n",
    "# Create missingness indicators for key biomarkers\n",
    "missing_flags = ['AFP', 'CA125', 'CA19-9', 'CA72-4', 'CEA', 'HE4', 'NEU']\n",
    "for col in missing_flags:\n",
    "    if col in data.columns:\n",
    "        data[f'{col}_missing'] = data[col].isna().astype(int)\n",
    "\n",
    "# Derive NEU% from complementary percentages if possible\n",
    "pct_complements = ['LYM%', 'MONO%', 'EO%', 'BASO%']\n",
    "if all(col in data.columns for col in pct_complements):\n",
    "    data['NEU_derived'] = 100 - data[pct_complements].sum(axis=1)\n",
    "    mask = data['NEU'].isna() & data['NEU_derived'].between(0, 100)\n",
    "    data.loc[mask, 'NEU'] = data.loc[mask, 'NEU_derived']\n",
    "    data = data.drop(columns='NEU_derived')  # Non-inplace for safety\n",
    "\n",
    "# Median imputation for low-missing-rate features\n",
    "low_missing_cols = ['AG', 'ALB', 'ALP', 'ALT', 'AST', 'DBIL', 'GGT', 'GLO', \n",
    "                    'IBIL', 'TBIL', 'TP', 'MPV', 'PCT', 'PDW', 'CO2CP']\n",
    "for col in low_missing_cols:\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col].fillna(data[col].median())\n",
    "\n",
    "# Iterative imputation for moderate-missing tumor markers\n",
    "tumor_markers = ['AFP', 'CA125', 'CA19-9', 'CEA', 'HE4']\n",
    "if any(col in data.columns for col in tumor_markers):\n",
    "    available_markers = [col for col in tumor_markers if col in data.columns]\n",
    "    imputer = IterativeImputer(\n",
    "        estimator=RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        max_iter=10, random_state=42\n",
    "    )\n",
    "    sub_df = data[available_markers].copy()\n",
    "    data[available_markers] = imputer.fit_transform(sub_df)\n",
    "\n",
    "# Median imputation for high-missing CA72-4\n",
    "if 'CA72-4' in data.columns:\n",
    "    data['CA72-4'] = data['CA72-4'].fillna(data['CA72-4'].median())\n",
    "\n",
    "# Iterative imputation for remaining NEU values\n",
    "if data['NEU'].isna().sum() > 0 and 'NEU' in data.columns:\n",
    "    ref_cols = ['LYM%', 'MONO%', 'EO%', 'BASO%', 'HGB', 'HCT', 'PLT']\n",
    "    available_refs = [col for col in ref_cols if col in data.columns]\n",
    "    temp_df = data[available_refs + ['NEU']].copy()\n",
    "    imputer_neu = IterativeImputer(\n",
    "        estimator=RandomForestRegressor(n_estimators=50, random_state=42),\n",
    "        random_state=42\n",
    "    )\n",
    "    neu_imputed = imputer_neu.fit_transform(temp_df)[:, -1]  # Last column is NEU\n",
    "    data['NEU'] = neu_imputed\n",
    "\n",
    "# Log-transform skewed tumor markers (using log1p for stability)\n",
    "log_cols = ['AFP', 'CA125', 'CA19-9', 'CEA', 'HE4', 'CA72-4']\n",
    "for col in log_cols:\n",
    "    if col in data.columns:\n",
    "        data[f'{col}_log'] = np.log1p(data[col])\n",
    "\n",
    "# Clip percentage columns to valid range [0, 100]\n",
    "pct_cols = [col for col in data.columns if '%' in col]\n",
    "data[pct_cols] = data[pct_cols].clip(lower=0, upper=100)\n",
    "\n",
    "# Save processed dataset\n",
    "output_path = \"cleaned_dataset.csv\"\n",
    "data.to_csv(output_path, index=False)\n",
    "print(f\"✅ Data cleaning and imputation complete. Saved to '{output_path}'.\")\n",
    "print(\"Remaining missing values:\\n\", data.isna().sum()[data.isna().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1311e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ovarian_cancer_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
